This package is a demonstration of a 'cold start' article recommendation system that utilizes a user's browsing history to perform Kmeans clustering of Doc2Vec vectors. With this information, the system generates a profile of the user's most important recent interests. The recommender system can then use the profile to make article recommendations that most closely match the user's interest. 

Many article recommendation systems currently use collaborative or content-based filtering or other methods that make recommendations based on the user's interaction with the site.  A collaborative filter recommendation system would create a user profile from the users previous interactions with the site and make recommendations based on the user profile's similarity to other user profiles. A collaborative system would recommend articles that other similar users had clicked on and/or rated, but which had not yet been viewed by the user. Content based systems compare the similarity of articles, often based on article tags. If a user clicks on article with tags 'business,'marketing','sales', a content based recommender system would recommend articles with the similar tags. Relying on tagging in this way is a major limitation for content based systems in two ways. First, having to provide tags can be burdensome. Secondly, a collection of tags may not accurately represent an article's subject matter. An article may have too few tags to convey the nuance of it's subject matter, or the tags themselves may be too general to use in making recommendations. Also, basic tagging systems weight all tags equally, so we may not get a sense of what the article is really about. A marketing article may use a example from baseball in one paragraph, but be tagged 'maketing', 'baseball.' This could lead a content based recommender to recommend articles about baseball, even though the article is really about marketing. Some content based recommenders have attempt to use latent Dirichlet allocation (LDA), such as LDA2VEC, to provide tag weighting to more accurately represent what percentage of each subject is in a given article. However, even this method is limited by the need to specify a certain number of topics to represent the article. 

The main obstacle facing both systems is the need for user intertaction before the system can make useful recommendations tailored to the user's interests, which is often referred to as the 'cold start problem.' This recommender system attempts to solve that problem by modeling a user's interests based on recent browsing history. Running the script will perform the following opertaions. 

1. Download a corpus of news articles retrieved from a variety of newspapers and populat blogs that represent a wide variety of topics (business,politics,sports,technology,entertainment etc). (237 MB). 
2. Create a Doc2Vec model from this corpus. Every article is represented by a 100 dimensional vector and occupies a 'point' in a vector space. The vector space represents a continuous space of semantic 'meanings' or 'topics' contained in the corpus. Broadly human intellible topics, such as business, sports etc, will occupy an 'area' within the vector space and articles touching on a given topic will be located near other articles touching on the same topic. 
3. Download the user's chrome history for a given number of days - default 2 days. (package only works for mac and windows chrome browsers for demo purposes) 
4. Filter the user history for articles that provide information about a user's interest. This filters out base web addresses, on the theory that specific links (articles) on a site will better indicate a user's interest. There are also a number of hardcoded filters in this demo. 
5. Download all the articles in user's filtered history. 
6. Create vectors for the articles in the user's filtered history using the doc2vec model created from the corpus. 
7. Use KMeans to cluster the vectors from the user's history. (Default 15 clusters). The ideal number of clusters for a given corpus and a given number of articles can be investigated with the Elbow method, or other methods mentioned in http://www.sthda.com/english/articles/29-cluster-validation-essentials/96-determining-the-optimal-number-of-clusters-3-must-know-methods/#elbow-method. For a given corpus, then, you can find the ideal number of clusters for a given number of articles in the user history. 
8. Get the most 'popular' vector clusters, as determined by the clusters with the greatest number of articles in them. The number of articles in a cluster serves as a representation for the level of user interest in the 'topic' of that cluster. 
